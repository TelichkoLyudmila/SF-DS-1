# 3. Соревнование на Kaggle по прогнозированию оценок Booking

## Оглавление  
1. Описание проекта 
2. Какой кейс решаем?
3. Краткая информация о данных
4. Этапы работы над проектом
5. Результат
6. Выводы

### Описание проекта    
Необходимо принять участие в соревновании и очистить данные/сформировать новые признаки таким образом, чтобы минимизировать целевой показатель MAPE. После спрогнозировать оценки пользователей для Booking посредством модель случайного леса

### Какой кейс решаем?    

1. Удаление строковых значений, очистка от пропущенных значений
2. Создание новых признаков, преобразование признаков 
3. Отбор признаков
4. Подбор и обучение модели, минимизация целевой переменной

**Условия соревнования:**  
Стандартное сорвенование в Kaggle, цель получить на test выборке минимальное отклонение от прогнозных данных

**Метрика качества**     
MAPE, вспомогательная MAE

**Что практикуем**     
Учимся обрабатывать раззные числовые и категориальные признаки, создавать из текстовых признаков категориальные, базово обучать модель, улучшать целевую переменную


### Краткая информация о данных
Данные на Kaggle представлены сразу в виде 2ух выборок: train и test, а результат предсказания модели необходимо загрузить в третий файл submission

### Этапы работы над проектом  
- Удаление строковых значений. 
- Очистка от пропущенных значений. 
- Создание новых признаков. 
- Преобразование признаков. 
- Отбор признаков. 
- Обучение модели, минимизация целевой переменной

### Результаты:  
MAPE улучшился с 14 до 12.5

### Выводы:  
Преобразование признаков, их стандартизация и кодирование могут существенно улучшить обучаемость модели
